{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"F:\\\\weather\\\\data txt\\\\txt\\\\\" #文件夹目录\n",
    "files= os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4006"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m=pd.read_table(path+files[0],delim_whitespace=True)#多个空值作分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m=data_m[data_m['Station_Id_C']==58135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_Id_C</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>WIN_S_Max</th>\n",
       "      <th>RHU</th>\n",
       "      <th>WIN_D_S_Max</th>\n",
       "      <th>PRS_Min</th>\n",
       "      <th>TEM_Min</th>\n",
       "      <th>...</th>\n",
       "      <th>PRS_Sea</th>\n",
       "      <th>VAP</th>\n",
       "      <th>PRE_1h</th>\n",
       "      <th>WIN_S_Inst_Max</th>\n",
       "      <th>PRS</th>\n",
       "      <th>WIN_D_INST_Max</th>\n",
       "      <th>TEM_Max</th>\n",
       "      <th>WIN_D_Avg_10mi</th>\n",
       "      <th>TEM</th>\n",
       "      <th>WIN_S_Avg_10mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Station_Id_C, Year, Mon, Day, Hour, WIN_S_Max, RHU, WIN_D_S_Max, PRS_Min, TEM_Min, PRS_Max, RHU_Min, PRS_Sea, VAP, PRE_1h, WIN_S_Inst_Max, PRS, WIN_D_INST_Max, TEM_Max, WIN_D_Avg_10mi, TEM, WIN_S_Avg_10mi]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-4a50092effcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdata_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Station_Id_C'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m58135\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata_m\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "while i<=len(files)-1:\n",
    "    dataset=pd.read_table(path+files[i],delim_whitespace=True)\n",
    "    data_set=dataset[dataset['Station_Id_C']==58135]\n",
    "    data_m=pd.concat([data_m,data_set])\n",
    "    i+=1\n",
    "else:print('merge complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m.to_csv('F:\\\\weather\\\\xw-sh.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 气象数据分省份整理并画图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 北京"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"F:\\\\weather\\\\data txt\\\\txt\\\\\" #气象文件夹目录\n",
    "files= os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "station=pd.read_excel('F:\\\\weather\\\\station.xlsx',usecols=[0,1]) #省份与站号的对应表\n",
    "station.rename(columns={'区站号':'Station_Id_C'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>省份</th>\n",
       "      <th>Station_Id_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>安徽</td>\n",
       "      <td>58015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>安徽</td>\n",
       "      <td>58016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>安徽</td>\n",
       "      <td>58102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>安徽</td>\n",
       "      <td>58107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>安徽</td>\n",
       "      <td>58108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   省份  Station_Id_C\n",
       "0  安徽         58015\n",
       "1  安徽         58016\n",
       "2  安徽         58102\n",
       "3  安徽         58107\n",
       "4  安徽         58108"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取所有北京站点数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_bj=station[station['省份']=='北京']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_bjs=sta_bj['Station_Id_C'].values.tolist() #dataframe转列表，方便后续使用lambda函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m=pd.read_table(path+files[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_bjs else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n=data_m[data_m['Station_Id_C']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "while i<=len(files)-1:\n",
    "    data_set=pd.read_table(path+files[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_bjs else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_n=pd.concat([data_n,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 193709 entries, 0 to 2879\n",
      "Data columns (total 37 columns):\n",
      "CLO_COV_LM        67340 non-null float64\n",
      "CLO_Cov           67340 non-null float64\n",
      "CLO_Cov_Low       67340 non-null float64\n",
      "Day               193709 non-null float64\n",
      "Day_Data          0 non-null object\n",
      "Hour              193709 non-null float64\n",
      "Hour_Data         0 non-null object\n",
      "Mon               193709 non-null float64\n",
      "Mon_Data          0 non-null object\n",
      "PRE_1h            193709 non-null float64\n",
      "PRS               193709 non-null float64\n",
      "PRS_Max           193709 non-null float64\n",
      "PRS_Min           193709 non-null float64\n",
      "PRS_Sea           193709 non-null float64\n",
      "RHU               193709 non-null object\n",
      "RHU_Min           193709 non-null float64\n",
      "Station_Id_C      193709 non-null object\n",
      "TEM               193709 non-null float64\n",
      "TEM_Max           193709 non-null float64\n",
      "TEM_Min           193709 non-null float64\n",
      "VAP               193709 non-null float64\n",
      "VIS               78527 non-null float64\n",
      "WEP_Now           67340 non-null float64\n",
      "WIN_D             0 non-null object\n",
      "WIN_D_Avg_10mi    106643 non-null float64\n",
      "WIN_D_Avg_2mi     86026 non-null float64\n",
      "WIN_D_INST_Max    193709 non-null float64\n",
      "WIN_D_S_Max       193709 non-null float64\n",
      "WIN_S             0 non-null object\n",
      "WIN_S_Avg_10mi    106643 non-null float64\n",
      "WIN_S_Avg_2mi     86026 non-null float64\n",
      "WIN_S_Inst_Max    193709 non-null float64\n",
      "WIN_S_Max         193709 non-null float64\n",
      "Year              193709 non-null float64\n",
      "Year_Data         0 non-null object\n",
      "tigan             96077 non-null float64\n",
      "windpower         96077 non-null float64\n",
      "dtypes: float64(29), object(8)\n",
      "memory usage: 56.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_n.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并后总计有193,709行数据，下一步进行数据整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj=data_n[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj=data_n[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 193709 entries, 0 to 2879\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    193709 non-null object\n",
      "Year            193709 non-null float64\n",
      "Mon             193709 non-null float64\n",
      "Day             193709 non-null float64\n",
      "Hour            193709 non-null float64\n",
      "RHU             193709 non-null object\n",
      "TEM             193709 non-null float64\n",
      "TEM_Max         193709 non-null float64\n",
      "TEM_Min         193709 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 14.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_bj.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj_drop=data_bj.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 173825 entries, 0 to 2879\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    173825 non-null object\n",
      "Year            173825 non-null float64\n",
      "Mon             173825 non-null float64\n",
      "Day             173825 non-null float64\n",
      "Hour            173825 non-null float64\n",
      "RHU             173825 non-null object\n",
      "TEM             173825 non-null float64\n",
      "TEM_Max         173825 non-null float64\n",
      "TEM_Min         173825 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 13.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_bj_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前193,709条数据，去重后173,825条数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_beijing=data_bj_drop[:]\n",
    "data_beijing['Station_Id_C']=data_beijing['Station_Id_C'].apply(lambda s :int(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__为方便后续数据整理，给每个地区增加2个数据标签：1.自然地理分区，2.省份自治区__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "省份              18\n",
       "Station_Id_C    18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta_bj.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_beijing_f=data_beijing[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#使用station数据集先标明各个站点的省份自治区，然后根据area数据集标明地理分区\n",
    "data_beijing_f['省份']='beijing'\n",
    "data_beijing_f['Area']='beijing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    173825\n",
       "Year            173825\n",
       "Mon             173825\n",
       "Day             173825\n",
       "Hour            173825\n",
       "RHU             173825\n",
       "TEM             173825\n",
       "TEM_Max         173825\n",
       "TEM_Min         173825\n",
       "省份              173825\n",
       "Area            173825\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_beijing_f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "北京地区站点共有18个，筛选后的数据173,825条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_beijing_f.to_csv('F:\\\\weather\\\\beijing.csv',index=False,encoding='utf_8_sig',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__核对温度是否符合：温度最大、最小、平均值之间逻辑关系：最小≤平均≤最大__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj_valid=data_bj_drop[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_bj_valid['valid1']=data_bj_drop['TEM_Max']-data_bj_drop['TEM']\n",
    "data_bj_valid['valid2']=data_bj_drop['TEM']-data_bj_drop['TEM_Min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid=data_bj_valid[(data_bj_valid['valid1']>=0) | (data_bj_valid['valid2']>=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 173825 entries, 0 to 2879\n",
      "Data columns (total 11 columns):\n",
      "Station_Id_C    173825 non-null object\n",
      "Year            173825 non-null float64\n",
      "Mon             173825 non-null float64\n",
      "Day             173825 non-null float64\n",
      "Hour            173825 non-null float64\n",
      "RHU             173825 non-null object\n",
      "TEM             173825 non-null float64\n",
      "TEM_Max         173825 non-null float64\n",
      "TEM_Min         173825 non-null float64\n",
      "valid1          173825 non-null float64\n",
      "valid2          173825 non-null float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 15.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_valid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见所有温度数据符合逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__统计“测定站-年-月-日”，当天数据量≥16条的保留（总共24条），其余剔除__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bjh=data_bj_drop[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bjh['Station_Id_C']=list(map(lambda s: str(s),data_bjh['Station_Id_C']))\n",
    "data_bjh['Year']=list(map(lambda s: str(s),data_bjh['Year']))\n",
    "data_bjh['Mon']=list(map(lambda s: str(s),data_bjh['Mon']))\n",
    "data_bjh['Day']=list(map(lambda s: str(s),data_bjh['Day']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bjh['SYMD']=data_bjh['Station_Id_C']+'-'+data_bjh['Year']+'-'+data_bjh['Mon']+'-'+data_bjh['Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid=data_bjh['SYMD'].value_counts()\n",
    "valid1=valid.to_frame('SYMD_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bjh1=pd.merge(data_bjh,valid1,left_on='SYMD',right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bjhf=data_bjh1[data_bjh1['SYMD_count']>=16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 165293 entries, 0 to 2879\n",
      "Data columns (total 11 columns):\n",
      "Station_Id_C    165293 non-null object\n",
      "Year            165293 non-null object\n",
      "Mon             165293 non-null object\n",
      "Day             165293 non-null object\n",
      "Hour            165293 non-null float64\n",
      "RHU             165293 non-null object\n",
      "TEM             165293 non-null float64\n",
      "TEM_Max         165293 non-null float64\n",
      "TEM_Min         165293 non-null float64\n",
      "SYMD            165293 non-null object\n",
      "SYMD_count      165293 non-null int64\n",
      "dtypes: float64(4), int64(1), object(6)\n",
      "memory usage: 15.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_bjhf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保留了足够重复数据165,293行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__统计“测定站-年-月”，当月数据量≥15天以上保留（总共28-31条），其余剔除__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_bjd=data_bjhf[:]\n",
    "\n",
    "# data_bjd['SYM']=data_bjd['Station_Id_C']+'-'+data_bjd['Year']+'-'+data_bjd['Mon']\n",
    "\n",
    "# data_bjd1=data_bjd.drop_duplicates('SYMD',keep='first')\n",
    "\n",
    "# valid=data_bjd1['SYM'].value_counts()\n",
    "# valid1=valid.to_frame('SYM_count')\n",
    "\n",
    "# data_bjd2=pd.merge(data_bjd,valid1,left_on='SYM',right_index=True,how='left')\n",
    "\n",
    "# data_bjdf=data_bjd2[data_bjd2['SYM_count']>=15]\n",
    "\n",
    "# data_bjdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保留了足够重复数据154,408行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__计算北京市温湿度指数（THI），取平均温度计算。计算公式：THI=0.81*温度+(0.99*温度-14.3)*相对湿度/100+46.3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj_final=data_bjhf[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "data_bj_final['Year']=list(map(lambda s: float(s),data_bj_final['Year']))\n",
    "data_bj_final['Mon']=list(map(lambda s: float(s),data_bj_final['Mon']))\n",
    "data_bj_final['Day']=list(map(lambda s: float(s),data_bj_final['Day']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_bj_final['THI']=0.81*data_bj_final['TEM']+(0.99*data_bj_final['TEM']-14.3)*(data_bj_final['RHU']/100)+46.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_Id_C</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>RHU</th>\n",
       "      <th>TEM</th>\n",
       "      <th>TEM_Max</th>\n",
       "      <th>TEM_Min</th>\n",
       "      <th>THI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54398</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>36.5675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54398</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>38.0503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54398</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>40.6854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54398</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>43.0307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54398</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station_Id_C    Year  Mon  Day  Hour RHU  TEM  TEM_Max  TEM_Min      THI\n",
       "0        54398  2016.0  1.0  4.0   0.0  43 -2.9     -2.4     -3.1  36.5675\n",
       "1        54398  2016.0  1.0  4.0   1.0  43 -1.7     -1.7     -3.1  38.0503\n",
       "2        54398  2016.0  1.0  4.0   2.0  36 -0.4     -0.4     -1.7  40.6854\n",
       "3        54398  2016.0  1.0  4.0   3.0  29  0.8      1.0     -0.4  43.0307\n",
       "4        54398  2016.0  1.0  4.0   4.0  27  1.1      1.3      0.5   43.624"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bj_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 165293 entries, 0 to 2879\n",
      "Data columns (total 10 columns):\n",
      "Station_Id_C    165293 non-null object\n",
      "Year            165293 non-null float64\n",
      "Mon             165293 non-null float64\n",
      "Day             165293 non-null float64\n",
      "Hour            165293 non-null float64\n",
      "RHU             165293 non-null object\n",
      "TEM             165293 non-null float64\n",
      "TEM_Max         165293 non-null float64\n",
      "TEM_Min         165293 non-null float64\n",
      "THI             165293 non-null object\n",
      "dtypes: float64(7), object(3)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_bj_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj_final.to_csv(\"F:\\\\weather\\\\BJ-plot.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__堆叠柱状图反映365天中THI的变化__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj_2017=data_bj_final[data_bj_final['Year']==2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 86430 entries, 0 to 2727\n",
      "Data columns (total 11 columns):\n",
      "Station_Id_C     86430 non-null object\n",
      "Year             86430 non-null float64\n",
      "Mon              86430 non-null float64\n",
      "Day              86430 non-null float64\n",
      "Hour             86430 non-null float64\n",
      "RHU              86430 non-null object\n",
      "TEM              86430 non-null float64\n",
      "TEM_Max          86430 non-null float64\n",
      "TEM_Min          86430 non-null float64\n",
      "WIN_D_Avg_2mi    35423 non-null float64\n",
      "THI              86430 non-null object\n",
      "dtypes: float64(8), object(3)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_bj_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "data_bj_2017['THI']=list(map(lambda s: float(s),data_bj_2017['THI']))\n",
    "data_bj_2017['Mon']=list(map(lambda s: int(s),data_bj_2017['Mon']))\n",
    "data_bj_2017['Day']=list(map(lambda s: int(s),data_bj_2017['Day']))\n",
    "data_bj_2017['Year']=list(map(lambda s: int(s),data_bj_2017['Year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj_y=data_bj_2017[data_bj_2017['THI']<=100] #删除THI异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_bj_y['Mon']=list(map(lambda s: str(s),data_bj_y['Mon']))\n",
    "data_bj_y['Day']=list(map(lambda s: str(s),data_bj_y['Day']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_bj_y['M-D']=data_bj_y['Mon']+'-'+data_bj_y['Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_THI=data_bj_y['THI'].groupby([data_bj_y['M-D']]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_THI=mean_THI.to_frame('mean_THI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj_f=pd.merge(data_bj_y,m_THI,left_on='M-D',right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_bj_y['Mon']=list(map(lambda s: int(s),data_bj_y['Mon']))\n",
    "data_bj_y['Day']=list(map(lambda s: int(s),data_bj_y['Day']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj_f1=data_bj_f.drop_duplicates(['Year','Mon','Day','mean_THI'],keep='first')[['Mon','Day','mean_THI']].sort_values(by=['Mon','Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bj_f1.to_csv(\"F:\\\\weather\\\\plot2017-BJ.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他地区气象数据整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中国地区可以分为以下：华东，华南，华北，华中，西南，西北，东北。各自对应许多省份，接下来按照以下几个区域对相应的气象数据进行整理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "area=pd.read_excel('F:\\\\weather\\\\station.xlsx',sheet_name=2,usecols=[0,1]) #省份与地理分区对应表\n",
    "area.rename(columns={'自然地理分区':'area','省市自治区':'province'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd=['上海','江苏','浙江','安徽','江西','山东','福建']\n",
    "hb=['北京','天津','山西','河北','内蒙古']\n",
    "hz=['河南','湖北','湖南']\n",
    "hn=['广东','广西','海南']\n",
    "xn=['四川','贵州','云南','重庆','西藏']\n",
    "xb=['陕西','甘肃','青海','宁夏','新疆']\n",
    "db=['黑龙江','吉林','辽宁']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 华东地区"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据筛选合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "sta_hd=station[station['省份']==hd[0]]['Station_Id_C'].values.tolist()\n",
    "i=1\n",
    "while i < len(hd):\n",
    "    sta_hd1=station[station['省份']==hd[i]]['Station_Id_C'].values.tolist()\n",
    "    sta_hd.extend(sta_hd1)\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2016='F:\\\\weather\\\\data txt\\\\2016txt\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2016=os.listdir('F:\\\\weather\\\\data txt\\\\2016txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m=pd.read_table(path_2016+file_2016[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_hd else 0 )\n",
    "data_hd=data_m[data_m['Station_Id_C']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "while i<=len(file_2016)-1:\n",
    "    data_set=pd.read_table(path_2016+file_2016[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_hd else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_hd=pd.concat([data_hd,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2017='F:\\\\weather\\\\data txt\\\\2017txt\\\\'\n",
    "\n",
    "file_2017=os.listdir('F:\\\\weather\\\\data txt\\\\2017txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_m=pd.read_table(path_2017+file_2017[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_hd else 0 )\n",
    "data_hd2017=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2017)-1:\n",
    "    data_set=pd.read_table(path_2017+file_2017[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_hd else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_hd2017=pd.concat([data_hd2017,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据质控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huad=data_hd[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4655373 entries, 0 to 17437\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 355.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huad.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huad_drop=data_huad.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3832313 entries, 0 to 17437\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 292.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huad_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前4,655,373条数据，去重后3,832,313条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huad2017=data_hd2017[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4121009 entries, 0 to 13384\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 314.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huad2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huad2017_drop=data_huad2017.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3590899 entries, 0 to 13384\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 274.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huad2017_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前4,121,009条数据，去重后3,590,899条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__两年数据合并__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huadong=pd.concat([data_huad_drop,data_huad2017_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7423212 entries, 0 to 13384\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    int64\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 726.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huadong['Station_Id_C']=data_huadong['Station_Id_C'].apply(lambda s:int(s))\n",
    "data_huadong.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__为方便后续数据整理，给每个地区增加2个数据标签：1.自然地理分区，2.省份自治区__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_hd_province=station[station['省份']==hd[0]]\n",
    "\n",
    "i=1\n",
    "while i < len(hd):\n",
    "    sta_hd_province1=station[station['省份']==hd[i]]\n",
    "    sta_hd_province=pd.concat([sta_hd_province,sta_hd_province1])\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "省份              477\n",
       "Station_Id_C    477\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta_hd_province.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用station数据集先标明各个站点的省份自治区，然后根据area数据集标明地理分区\n",
    "data_huadong_f=pd.merge(data_huadong,sta_hd_province,on='Station_Id_C',how='outer')\n",
    "data_huadong_f['Area']='huadong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    7423212\n",
       "Year            7423212\n",
       "Mon             7423212\n",
       "Day             7423212\n",
       "Hour            7423212\n",
       "RHU             7423212\n",
       "TEM             7423212\n",
       "TEM_Max         7423212\n",
       "TEM_Min         7423212\n",
       "省份              7423212\n",
       "Area            7423212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_huadong_f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "华东地区站点共有477个，筛选后的数据7,423,212条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huadong_f.to_csv('F:\\\\weather\\\\huadong.csv',index=False,encoding='utf_8_sig',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 华南地区"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_hn=station[station['省份']==hn[0]]['Station_Id_C'].values.tolist()\n",
    "i=1\n",
    "while i < len(hn):\n",
    "    sta_hn1=station[station['省份']==hn[i]]['Station_Id_C'].values.tolist()\n",
    "    sta_hn.extend(sta_hn1)\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2016+file_2016[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_hn else 0 )\n",
    "data_hn2016=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2016)-1:\n",
    "    data_set=pd.read_table(path_2016+file_2016[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_hn else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_hn2016=pd.concat([data_hn2016,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2017+file_2017[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_hn else 0 )\n",
    "data_hn2017=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2017)-1:\n",
    "    data_set=pd.read_table(path_2017+file_2017[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_hn else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_hn2017=pd.concat([data_hn2017,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据质控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huan2016=data_hn2016[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1630580 entries, 0 to 2559\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    1630580 non-null object\n",
      "Year            1630580 non-null object\n",
      "Mon             1630580 non-null object\n",
      "Day             1630580 non-null object\n",
      "Hour            1630580 non-null object\n",
      "RHU             1630580 non-null object\n",
      "TEM             1630580 non-null float64\n",
      "TEM_Max         1630580 non-null float64\n",
      "TEM_Min         1630580 non-null float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 124.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huan2016.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huan2016_drop=data_huan2016.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1375748 entries, 0 to 2559\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    1375748 non-null object\n",
      "Year            1375748 non-null object\n",
      "Mon             1375748 non-null object\n",
      "Day             1375748 non-null object\n",
      "Hour            1375748 non-null object\n",
      "RHU             1375748 non-null object\n",
      "TEM             1375748 non-null float64\n",
      "TEM_Max         1375748 non-null float64\n",
      "TEM_Min         1375748 non-null float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 105.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huan2016_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前1,630,580条数据，去重后1,375,748条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huan2017=data_hn2017[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 789543 entries, 0 to 2527\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    789543 non-null object\n",
      "Year            789543 non-null float64\n",
      "Mon             789543 non-null float64\n",
      "Day             789543 non-null float64\n",
      "Hour            789543 non-null float64\n",
      "RHU             789543 non-null object\n",
      "TEM             789543 non-null float64\n",
      "TEM_Max         789543 non-null float64\n",
      "TEM_Min         789543 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 60.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huan2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huan2017_drop=data_huan2017.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 686675 entries, 0 to 2527\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    686675 non-null object\n",
      "Year            686675 non-null float64\n",
      "Mon             686675 non-null float64\n",
      "Day             686675 non-null float64\n",
      "Hour            686675 non-null float64\n",
      "RHU             686675 non-null object\n",
      "TEM             686675 non-null float64\n",
      "TEM_Max         686675 non-null float64\n",
      "TEM_Min         686675 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 52.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huan2017_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前789,543条数据，去重后686,675条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__两年数据合并__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huanan=pd.concat([data_huan2016_drop,data_huan2017_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    2062423\n",
       "Year            2062423\n",
       "Mon             2062423\n",
       "Day             2062423\n",
       "Hour            2062423\n",
       "RHU             2062423\n",
       "TEM             2062423\n",
       "TEM_Max         2062423\n",
       "TEM_Min         2062423\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_huanan['Station_Id_C']=data_huanan['Station_Id_C'].apply(lambda s:int(s))\n",
    "data_huanan.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__为方便后续数据整理，给每个地区增加2个数据标签：1.自然地理分区，2.省份自治区__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_hn_province=station[station['省份']==hn[0]]\n",
    "\n",
    "i=1\n",
    "while i < len(hn):\n",
    "    sta_hn_province1=station[station['省份']==hn[i]]\n",
    "    sta_hn_province=pd.concat([sta_hn_province,sta_hn_province1])\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "省份              177\n",
       "Station_Id_C    177\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta_hn_province.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用station数据集先标明各个站点的省份自治区，然后根据area数据集标明地理分区\n",
    "data_huanan_f=pd.merge(data_huanan,sta_hn_province,on='Station_Id_C',how='outer')\n",
    "data_huanan_f['Area']='huanan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    2062423\n",
       "Year            2062423\n",
       "Mon             2062423\n",
       "Day             2062423\n",
       "Hour            2062423\n",
       "RHU             2062423\n",
       "TEM             2062423\n",
       "TEM_Max         2062423\n",
       "TEM_Min         2062423\n",
       "省份              2062423\n",
       "Area            2062423\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_huanan_f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "华南地区站点共有177个，筛选后的数据2,062,423条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huanan_f.to_csv('F:\\\\weather\\\\huanan.csv',index=False,encoding='utf_8_sig',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 华北地区"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_hb=station[station['省份']==hb[0]]['Station_Id_C'].values.tolist()\n",
    "i=1\n",
    "while i < len(hb):\n",
    "    sta_hb1=station[station['省份']==hb[i]]['Station_Id_C'].values.tolist()\n",
    "    sta_hb.extend(sta_hb1)\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2016+file_2016[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_hb else 0 )\n",
    "data_hb2016=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2016)-1:\n",
    "    data_set=pd.read_table(path_2016+file_2016[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_hb else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_hb2016=pd.concat([data_hb2016,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2017+file_2017[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_hb else 0 )\n",
    "data_hb2017=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2017)-1:\n",
    "    data_set=pd.read_table(path_2017+file_2017[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_hb else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_hb2017=pd.concat([data_hb2017,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据质控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huab2016=data_hb2016[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3764888 entries, 0 to 15999\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 287.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huab2016.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huab2016_drop=data_huab2016.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2976570 entries, 0 to 15999\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 227.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huab2016_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前3,764,888条数据，去重后2,976,570条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huab2017=data_hb2017[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3393438 entries, 0 to 14709\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 258.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huab2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huab2017_drop=data_huab2017.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2854575 entries, 0 to 14709\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 217.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huab2017_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前3,393,438条数据，去重后2,854,575条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__两年数据合并__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huabei=pd.concat([data_huab2016_drop,data_huab2017_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    5831145\n",
       "Year            5831145\n",
       "Mon             5831145\n",
       "Day             5831145\n",
       "Hour            5831145\n",
       "RHU             5831145\n",
       "TEM             5831145\n",
       "TEM_Max         5831145\n",
       "TEM_Min         5831145\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_huabei['Station_Id_C']=data_huabei['Station_Id_C'].apply(lambda s:int(s))\n",
    "data_huabei.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__为方便后续数据整理，给每个地区增加2个数据标签：1.自然地理分区，2.省份自治区__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_hb_province=station[station['省份']==hb[0]]\n",
    "\n",
    "i=1\n",
    "while i < len(hb):\n",
    "    sta_hb_province1=station[station['省份']==hb[i]]\n",
    "    sta_hb_province=pd.concat([sta_hb_province,sta_hb_province1])\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "省份              379\n",
       "Station_Id_C    379\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta_hb_province.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用station数据集先标明各个站点的省份自治区，然后根据area数据集标明地理分区\n",
    "data_huabei_f=pd.merge(data_huabei,sta_hb_province,on='Station_Id_C',how='outer')\n",
    "data_huabei_f['Area']='huabei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    5831145\n",
       "Year            5831145\n",
       "Mon             5831145\n",
       "Day             5831145\n",
       "Hour            5831145\n",
       "RHU             5831145\n",
       "TEM             5831145\n",
       "TEM_Max         5831145\n",
       "TEM_Min         5831145\n",
       "省份              5831145\n",
       "Area            5831145\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_huabei_f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "华北地区站点共有379个，筛选后的数据5,831,145条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huabei_f.to_csv('F:\\\\weather\\\\huabei.csv',index=False,encoding='utf_8_sig',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 华中地区"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_hz=station[station['省份']==hz[0]]['Station_Id_C'].values.tolist()\n",
    "i=1\n",
    "while i < len(hz):\n",
    "    sta_hz1=station[station['省份']==hz[i]]['Station_Id_C'].values.tolist()\n",
    "    sta_hz.extend(sta_hz1)\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2016+file_2016[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_hz else 0 )\n",
    "data_hz2016=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2016)-1:\n",
    "    data_set=pd.read_table(path_2016+file_2016[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_hz else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_hz2016=pd.concat([data_hz2016,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2017+file_2017[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_hz else 0 )\n",
    "data_hz2017=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2017)-1:\n",
    "    data_set=pd.read_table(path_2017+file_2017[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_hz else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_hz2017=pd.concat([data_hz2017,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据质控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huaz2016=data_hz2016[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2497777 entries, 0 to 13437\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 190.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huaz2016.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huaz2016_drop=data_huaz2016.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2068829 entries, 0 to 13437\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 157.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huaz2016_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前2,497,777条数据，去重后2,068,829条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huaz2017=data_hz2017[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1534743 entries, 0 to 13271\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    1534743 non-null object\n",
      "Year            1534743 non-null float64\n",
      "Mon             1534743 non-null float64\n",
      "Day             1534743 non-null float64\n",
      "Hour            1534743 non-null float64\n",
      "RHU             1534743 non-null object\n",
      "TEM             1534743 non-null float64\n",
      "TEM_Max         1534743 non-null float64\n",
      "TEM_Min         1534743 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 117.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huaz2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huaz2017_drop=data_huaz2017.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1367835 entries, 0 to 13271\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    1367835 non-null object\n",
      "Year            1367835 non-null float64\n",
      "Mon             1367835 non-null float64\n",
      "Day             1367835 non-null float64\n",
      "Hour            1367835 non-null float64\n",
      "RHU             1367835 non-null object\n",
      "TEM             1367835 non-null float64\n",
      "TEM_Max         1367835 non-null float64\n",
      "TEM_Min         1367835 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 104.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_huaz2017_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前1,534,743条数据，去重后1,367,835条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__两年数据合并__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_huazhong=pd.concat([data_huaz2016_drop,data_huaz2017_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    3436664\n",
       "Year            3436664\n",
       "Mon             3436664\n",
       "Day             3436664\n",
       "Hour            3436664\n",
       "RHU             3436664\n",
       "TEM             3436664\n",
       "TEM_Max         3436664\n",
       "TEM_Min         3436664\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_huazhong['Station_Id_C']=data_huazhong['Station_Id_C'].apply(lambda s:int(s))\n",
    "data_huazhong.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__为方便后续数据整理，给每个地区增加2个数据标签：1.自然地理分区，2.省份自治区__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_hz_province=station[station['省份']==hz[0]]\n",
    "\n",
    "i=1\n",
    "while i < len(hz):\n",
    "    sta_hz_province1=station[station['省份']==hz[i]]\n",
    "    sta_hz_province=pd.concat([sta_hz_province,sta_hz_province1])\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "省份              272\n",
       "Station_Id_C    272\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta_hz_province.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用station数据集先标明各个站点的省份自治区，然后根据area数据集标明地理分区\n",
    "data_huazhong_f=pd.merge(data_huazhong,sta_hz_province,on='Station_Id_C',how='outer')\n",
    "data_huazhong_f['Area']='huazhong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    3436664\n",
       "Year            3436664\n",
       "Mon             3436664\n",
       "Day             3436664\n",
       "Hour            3436664\n",
       "RHU             3436664\n",
       "TEM             3436664\n",
       "TEM_Max         3436664\n",
       "TEM_Min         3436664\n",
       "省份              3436664\n",
       "Area            3436664\n",
       "dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_huazhong_f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "华中地区站点共有272个，筛选后的数据3,436,664条。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 西南地区"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_xn=station[station['省份']==xn[0]]['Station_Id_C'].values.tolist()\n",
    "i=1\n",
    "while i < len(xn):\n",
    "    sta_xn1=station[station['省份']==xn[i]]['Station_Id_C'].values.tolist()\n",
    "    sta_xn.extend(sta_xn1)\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2016+file_2016[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_xn else 0 )\n",
    "data_xn2016=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2016)-1:\n",
    "    data_set=pd.read_table(path_2016+file_2016[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_xn else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_xn2016=pd.concat([data_xn2016,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2017+file_2017[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_xn else 0 )\n",
    "data_xn2017=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2017)-1:\n",
    "    data_set=pd.read_table(path_2017+file_2017[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_xn else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_xn2017=pd.concat([data_xn2017,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据质控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xin2016=data_xn2016[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3532255 entries, 0 to 5543\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 269.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_xin2016.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xin2016_drop=data_xin2016.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2916733 entries, 0 to 5543\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 222.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_xin2016_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前3,532,255条数据，去重后2,916,733条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xin2017=data_xn2017[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2562344 entries, 0 to 3633\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 195.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_xin2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xin2017_drop=data_xin2017.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2220374 entries, 0 to 3633\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 169.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_xin2017_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前2,562,344条数据，去重后2,220,374条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__两年数据合并__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xinan=pd.concat([data_xin2016_drop,data_xin2017_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    5137107\n",
       "Year            5137107\n",
       "Mon             5137107\n",
       "Day             5137107\n",
       "Hour            5137107\n",
       "RHU             5137107\n",
       "TEM             5137107\n",
       "TEM_Max         5137107\n",
       "TEM_Min         5137107\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xinan['Station_Id_C']=data_xinan['Station_Id_C'].apply(lambda s:int(s))\n",
    "data_xinan.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__为方便后续数据整理，给每个地区增加2个数据标签：1.自然地理分区，2.省份自治区__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_xn_province=station[station['省份']==xn[0]]\n",
    "\n",
    "i=1\n",
    "while i < len(xn):\n",
    "    sta_xn_province1=station[station['省份']==xn[i]]\n",
    "    sta_xn_province=pd.concat([sta_xn_province,sta_xn_province1])\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "省份              387\n",
       "Station_Id_C    387\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta_xn_province.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用station数据集先标明各个站点的省份自治区，然后根据area数据集标明地理分区\n",
    "data_xinan_f=pd.merge(data_xinan,sta_xn_province,on='Station_Id_C',how='outer')\n",
    "data_xinan_f['Area']='xinan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    5137107\n",
       "Year            5137107\n",
       "Mon             5137107\n",
       "Day             5137107\n",
       "Hour            5137107\n",
       "RHU             5137107\n",
       "TEM             5137107\n",
       "TEM_Max         5137107\n",
       "TEM_Min         5137107\n",
       "省份              5137107\n",
       "Area            5137107\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xinan_f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "西南地区站点共有387个，筛选后的数据5,137,107条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xinan_f.to_csv('F:\\\\weather\\\\xinan.csv',index=False,encoding='utf_8_sig',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 西北地区"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_xb=station[station['省份']==xb[0]]['Station_Id_C'].values.tolist()\n",
    "i=1\n",
    "while i < len(xb):\n",
    "    sta_xb1=station[station['省份']==xb[i]]['Station_Id_C'].values.tolist()\n",
    "    sta_xb.extend(sta_xb1)\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2016+file_2016[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_xb else 0 )\n",
    "data_xb2016=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2016)-1:\n",
    "    data_set=pd.read_table(path_2016+file_2016[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_xb else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_xb2016=pd.concat([data_xb2016,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2017+file_2017[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_xb else 0 )\n",
    "data_xb2017=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2017)-1:\n",
    "    data_set=pd.read_table(path_2017+file_2017[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_xb else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_xb2017=pd.concat([data_xb2017,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据质控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xib2016=data_xb2016[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2568063 entries, 0 to 10539\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 195.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_xib2016.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xib2016_drop=data_xib2016.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2184481 entries, 0 to 10539\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 166.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_xib2016_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前2,568,063条数据，去重后2,184,481条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xib2017=data_xb2017[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1764801 entries, 0 to 10008\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 134.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_xib2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xib2017_drop=data_xib2017.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1593979 entries, 0 to 10008\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    1593979 non-null object\n",
      "Year            1593979 non-null float64\n",
      "Mon             1593979 non-null float64\n",
      "Day             1593979 non-null float64\n",
      "Hour            1593979 non-null float64\n",
      "RHU             1593979 non-null object\n",
      "TEM             1593979 non-null float64\n",
      "TEM_Max         1593979 non-null float64\n",
      "TEM_Min         1593979 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 121.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_xib2017_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前1,764,801条数据，去重后1,593,979条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__两年数据合并__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xibei=pd.concat([data_xib2016_drop,data_xib2017_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    3778460\n",
       "Year            3778460\n",
       "Mon             3778460\n",
       "Day             3778460\n",
       "Hour            3778460\n",
       "RHU             3778460\n",
       "TEM             3778460\n",
       "TEM_Max         3778460\n",
       "TEM_Min         3778460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xibei['Station_Id_C']=data_xibei['Station_Id_C'].apply(lambda s:int(s))\n",
    "data_xibei.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__为方便后续数据整理，给每个地区增加2个数据标签：1.自然地理分区，2.省份自治区__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_xb_province=station[station['省份']==xb[0]]\n",
    "\n",
    "i=1\n",
    "while i < len(xb):\n",
    "    sta_xb_province1=station[station['省份']==xb[i]]\n",
    "    sta_xb_province=pd.concat([sta_xb_province,sta_xb_province1])\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "省份              290\n",
       "Station_Id_C    290\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta_xb_province.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用station数据集先标明各个站点的省份自治区，然后根据area数据集标明地理分区\n",
    "data_xibei_f=pd.merge(data_xibei,sta_xb_province,on='Station_Id_C',how='outer')\n",
    "data_xibei_f['Area']='xibei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    3778460\n",
       "Year            3778460\n",
       "Mon             3778460\n",
       "Day             3778460\n",
       "Hour            3778460\n",
       "RHU             3778460\n",
       "TEM             3778460\n",
       "TEM_Max         3778460\n",
       "TEM_Min         3778460\n",
       "省份              3778460\n",
       "Area            3778460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xibei_f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "西北地区站点共有290个，筛选后的数据3,778,460条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xibei_f.to_csv('F:\\\\weather\\\\xibei.csv',index=False,encoding='utf_8_sig',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 东北地区"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_db=station[station['省份']==db[0]]['Station_Id_C'].values.tolist()\n",
    "i=1\n",
    "while i < len(db):\n",
    "    sta_db1=station[station['省份']==db[i]]['Station_Id_C'].values.tolist()\n",
    "    sta_db.extend(sta_db1)\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2016+file_2016[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_db else 0 )\n",
    "data_db2016=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2016)-1:\n",
    "    data_set=pd.read_table(path_2016+file_2016[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_db else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_db2016=pd.concat([data_db2016,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge complete!\n"
     ]
    }
   ],
   "source": [
    "data_m=pd.read_table(path_2017+file_2017[0],delim_whitespace=True)#多个空值作分隔符,读取第一个文件\n",
    "data_m['Station_Id_C']=data_m['Station_Id_C'].apply(lambda s: s if s in sta_db else 0 )\n",
    "data_db2017=data_m[data_m['Station_Id_C']>0]\n",
    "\n",
    "i=1\n",
    "while i<=len(file_2017)-1:\n",
    "    data_set=pd.read_table(path_2017+file_2017[i],delim_whitespace=True)\n",
    "    data_set['Station_Id_C']=data_set['Station_Id_C'].apply(lambda s: s if s in sta_db else 0 )\n",
    "    data_sets=data_set[data_set['Station_Id_C']>0]\n",
    "    data_db2017=pd.concat([data_db2017,data_sets])\n",
    "    i+=1\n",
    "else:\n",
    "    print('merge complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据质控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dongb2016=data_db2016[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1812547 entries, 0 to 13116\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    object\n",
      "Year            float64\n",
      "Mon             float64\n",
      "Day             float64\n",
      "Hour            float64\n",
      "RHU             object\n",
      "TEM             float64\n",
      "TEM_Max         float64\n",
      "TEM_Min         float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 138.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_dongb2016.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dongb2016_drop=data_dongb2016.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1503661 entries, 0 to 13116\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    1503661 non-null object\n",
      "Year            1503661 non-null float64\n",
      "Mon             1503661 non-null float64\n",
      "Day             1503661 non-null float64\n",
      "Hour            1503661 non-null float64\n",
      "RHU             1503661 non-null object\n",
      "TEM             1503661 non-null float64\n",
      "TEM_Max         1503661 non-null float64\n",
      "TEM_Min         1503661 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 114.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_dongb2016_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前1,812,547条数据，去重后1,503,661条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017年__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保留关键指标：相对湿度（0~100），平均、最大、最小温度（-50~+100），风速（RHU、TEM、TEM_Max、TEM_Min、WIN_D_Avg_2mi）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dongb2017=data_db2017[['Station_Id_C','Year','Mon','Day','Hour','RHU','TEM','TEM_Max','TEM_Min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1603234 entries, 0 to 12072\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    1603234 non-null object\n",
      "Year            1603234 non-null float64\n",
      "Mon             1603234 non-null float64\n",
      "Day             1603234 non-null float64\n",
      "Hour            1603234 non-null float64\n",
      "RHU             1603234 non-null object\n",
      "TEM             1603234 non-null float64\n",
      "TEM_Max         1603234 non-null float64\n",
      "TEM_Min         1603234 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 122.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_dongb2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__删除重复值：每次导出数据可能有重叠，合并“测定站-年-月-日-时间”删重__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dongb2017_drop=data_dongb2017.drop_duplicates(['Station_Id_C','Year','Mon','Day','Hour'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1385171 entries, 0 to 12072\n",
      "Data columns (total 9 columns):\n",
      "Station_Id_C    1385171 non-null object\n",
      "Year            1385171 non-null float64\n",
      "Mon             1385171 non-null float64\n",
      "Day             1385171 non-null float64\n",
      "Hour            1385171 non-null float64\n",
      "RHU             1385171 non-null object\n",
      "TEM             1385171 non-null float64\n",
      "TEM_Max         1385171 non-null float64\n",
      "TEM_Min         1385171 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 105.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_dongb2017_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去重前1,603,234条数据，去重后1,385,171条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__两年数据合并__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dongbei=pd.concat([data_dongb2016_drop,data_dongb2017_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    2888832\n",
       "Year            2888832\n",
       "Mon             2888832\n",
       "Day             2888832\n",
       "Hour            2888832\n",
       "RHU             2888832\n",
       "TEM             2888832\n",
       "TEM_Max         2888832\n",
       "TEM_Min         2888832\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dongbei['Station_Id_C']=data_dongbei['Station_Id_C'].apply(lambda s:int(s))\n",
    "data_dongbei.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__为方便后续数据整理，给每个地区增加2个数据标签：1.自然地理分区，2.省份自治区__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_db_province=station[station['省份']==db[0]]\n",
    "\n",
    "i=1\n",
    "while i < len(db):\n",
    "    sta_db_province1=station[station['省份']==db[i]]\n",
    "    sta_db_province=pd.concat([sta_db_province,sta_db_province1])\n",
    "    i+=1    #提取所有华东省份的站点ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "省份              186\n",
       "Station_Id_C    186\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta_db_province.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用station数据集先标明各个站点的省份自治区，然后根据area数据集标明地理分区\n",
    "data_dongbei_f=pd.merge(data_dongbei,sta_db_province,on='Station_Id_C',how='outer')\n",
    "data_dongbei_f['Area']='dongbei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_Id_C    2888832\n",
       "Year            2888832\n",
       "Mon             2888832\n",
       "Day             2888832\n",
       "Hour            2888832\n",
       "RHU             2888832\n",
       "TEM             2888832\n",
       "TEM_Max         2888832\n",
       "TEM_Min         2888832\n",
       "省份              2888832\n",
       "Area            2888832\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dongbei_f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "华中地区站点共有186个，筛选后的数据2,888,832条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dongbei_f.to_csv('F:\\\\weather\\\\dongbei.csv',index=False,encoding='utf_8_sig',sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
